{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4c819",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T09:07:50.647949Z",
     "iopub.status.busy": "2025-12-16T09:07:50.647601Z",
     "iopub.status.idle": "2025-12-16T09:10:44.123767Z",
     "shell.execute_reply": "2025-12-16T09:10:44.122696Z"
    },
    "papermill": {
     "duration": 173.48219,
     "end_time": "2025-12-16T09:10:44.126032",
     "exception": false,
     "start_time": "2025-12-16T09:07:50.643842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected target: sentiment\n",
      "Task: classification | y dtype: object | unique: 2\n",
      "num_cols: 0 cat_cols: 0 text_cols: 1\n",
      "text_cols example: ['review']\n",
      "Validation Accuracy: 0.9008 | Macro-F1: 0.9007\n",
      "Saved: submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id sentiment\n",
       "0   0  negative\n",
       "1   1  positive\n",
       "2   2  negative\n",
       "3   3  negative\n",
       "4   4  positive"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "\n",
    "# ===== 1) 讀資料 =====\n",
    "DATA_DIR = \"/kaggle/input/imdb-rotten-tomatoes\"  \n",
    "train_path = os.path.join(DATA_DIR, \"train.csv\")\n",
    "test_path  = os.path.join(DATA_DIR, \"test.csv\")\n",
    "sub_path   = os.path.join(DATA_DIR, \"sample_submission.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test  = pd.read_csv(test_path)\n",
    "sub   = pd.read_csv(sub_path)\n",
    "\n",
    "# ===== 2) 自動找 target 欄位 =====\n",
    "target_candidates = list(set(train.columns) - set(test.columns))\n",
    "if len(target_candidates) != 1:\n",
    "    if sub.shape[1] >= 2:\n",
    "        target = sub.columns[1]\n",
    "        print(\"[Warn] 無法用欄位差唯一決定 target，改用 sample_submission 第2欄推定:\", target)\n",
    "    else:\n",
    "        raise ValueError(f\"找不到唯一 target 候選：{target_candidates}，請檢查 train/test 欄位\")\n",
    "else:\n",
    "    target = target_candidates[0]\n",
    "    print(\"Detected target:\", target)\n",
    "\n",
    "X = train.drop(columns=[target])\n",
    "y = train[target]\n",
    "\n",
    "# ===== 3) 判斷任務：分類 vs 回歸 =====\n",
    "# 規則：若 y 是數字但唯一值很少(<=20 且都是整數)，多半是分類；否則回歸\n",
    "is_numeric = pd.api.types.is_numeric_dtype(y)\n",
    "unique_vals = y.dropna().unique()\n",
    "task = \"regression\"\n",
    "\n",
    "if (not is_numeric) or (len(unique_vals) <= 20 and np.all(np.equal(np.mod(unique_vals, 1), 0))):\n",
    "    task = \"classification\"\n",
    "\n",
    "print(\"Task:\", task, \"| y dtype:\", y.dtype, \"| unique:\", len(unique_vals))\n",
    "\n",
    "# ===== 4) 欄位型態分流：文字 / 類別 / 數值 =====\n",
    "text_cols = []\n",
    "cat_cols = []\n",
    "num_cols = []\n",
    "\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == \"object\":\n",
    "        # 文字欄位：用平均字數判斷（>4 個詞就當文字；否則當類別）\n",
    "        sample = X[c].dropna().astype(str).head(200)\n",
    "        avg_words = sample.apply(lambda s: len(s.split())).mean() if len(sample) else 0\n",
    "        if avg_words >= 5:\n",
    "            text_cols.append(c)\n",
    "        else:\n",
    "            cat_cols.append(c)\n",
    "    else:\n",
    "        num_cols.append(c)\n",
    "\n",
    "print(\"num_cols:\", len(num_cols), \"cat_cols:\", len(cat_cols), \"text_cols:\", len(text_cols))\n",
    "if text_cols:\n",
    "    print(\"text_cols example:\", text_cols[:5])\n",
    "\n",
    "# ===== 5) 前處理器：數值補值 + 類別 one-hot + 文字 tf-idf =====\n",
    "numeric_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "categorical_tf = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# 文字：多欄文字先合併成一欄再 TF-IDF（簡單而有效）\n",
    "def join_text_columns(df):\n",
    "    out = df[text_cols].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "    return out\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "text_tf = Pipeline(steps=[\n",
    "    (\"join\", FunctionTransformer(lambda df: join_text_columns(df), validate=False)),\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        max_features=50000,\n",
    "        ngram_range=(1,3),\n",
    "        min_df=2\n",
    "    ))\n",
    "])\n",
    "\n",
    "transformers = []\n",
    "if num_cols:\n",
    "    transformers.append((\"num\", numeric_tf, num_cols))\n",
    "if cat_cols:\n",
    "    transformers.append((\"cat\", categorical_tf, cat_cols))\n",
    "if text_cols:\n",
    "    transformers.append((\"txt\", text_tf, text_cols))\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder=\"drop\",\n",
    "    sparse_threshold=0.5\n",
    ")\n",
    "\n",
    "# ===== 6) 模型：分類/回歸各給一個穩健 baseline =====\n",
    "if task == \"classification\":\n",
    "    model = LogisticRegression(max_iter=3000, n_jobs=-1)\n",
    "else:\n",
    "    model = Ridge(alpha=2.0)  # 文字回歸\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"model\", model)\n",
    "])\n",
    "\n",
    "# ===== 7) 本地切分驗證 =====\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42,\n",
    "    stratify=y if task==\"classification\" and len(unique_vals) > 1 else None\n",
    ")\n",
    "\n",
    "clf.fit(X_tr, y_tr)\n",
    "pred_va = clf.predict(X_va)\n",
    "\n",
    "if task == \"classification\":\n",
    "    acc = accuracy_score(y_va, pred_va)\n",
    "    f1 = f1_score(y_va, pred_va, average=\"macro\")\n",
    "    print(f\"Validation Accuracy: {acc:.4f} | Macro-F1: {f1:.4f}\")\n",
    "else:\n",
    "    rmse = mean_squared_error(y_va, pred_va, squared=False)\n",
    "    mae  = mean_absolute_error(y_va, pred_va)\n",
    "    print(f\"Validation RMSE: {rmse:.4f} | MAE: {mae:.4f}\")\n",
    "\n",
    "# ===== 8) 全資料重訓 + 產生 submission =====\n",
    "clf.fit(X, y)\n",
    "\n",
    "need_proba = False\n",
    "if task == \"classification\":\n",
    "    sub_col = sub.columns[1]\n",
    "    # 嘗試把 sample_submission 的目標欄強制轉成數字；解析失敗會是 NaN\n",
    "    sub_vals_num = pd.to_numeric(sub[sub_col], errors='coerce')\n",
    "\n",
    "    # 1) 型別或內容看起來像浮點數\n",
    "    looks_numeric = pd.api.types.is_float_dtype(sub[sub_col]) or sub_vals_num.notna().all()\n",
    "\n",
    "    # 2) 值域是否 (0,1) 的機率（用 inclusive=\"both\" 含 0/1，且排除 NaN）\n",
    "    looks_like_prob = sub_vals_num.dropna().between(0, 1, inclusive=\"both\").all() and sub_vals_num.notna().any()\n",
    "\n",
    "    # 3) 模型是否提供 predict_proba\n",
    "    supports_proba = hasattr(clf.named_steps[\"model\"], \"predict_proba\")\n",
    "\n",
    "    if supports_proba and (looks_numeric and looks_like_prob):\n",
    "        need_proba = True\n",
    "    else:\n",
    "        need_proba = False\n",
    "\n",
    "\n",
    "if task == \"classification\" and need_proba:\n",
    "    test_pred = clf.predict_proba(test)[:, -1]\n",
    "else:\n",
    "    test_pred = clf.predict(test)\n",
    "\n",
    "submission = sub.copy()\n",
    "submission[submission.columns[1]] = test_pred\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Saved: submission.csv\")\n",
    "submission.head()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13426318,
     "sourceId": 112635,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 181.219584,
   "end_time": "2025-12-16T09:10:46.849661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-16T09:07:45.630077",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
